{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab06: Transforming and Comparing Data\n",
    "\n",
    "This lab is presented with some revisions from [Dennis Sun at Cal Poly](https://web.calpoly.edu/~dsun09/index.html) and his [Data301 Course](http://users.csc.calpoly.edu/~dsun09/data301/lectures.html)\n",
    "\n",
    "### When you have filled out all the questions, submit via [Tulane Canvas](https://tulane.instructure.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will transform and combine existing variables to obtain new variables. Our examples are drawn from a data set of house prices in Ames, Iowa.  This data set is stored in a tab-separated values file.  For more information about the variables in this data set, please refer to the [data documentation](https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "df = pd.read_csv('../data/ames.tsv', sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Transformations\n",
    "\n",
    "### Quantitative Variables\n",
    "\n",
    "There are several reasons to transform quantitative variables, including:\n",
    "\n",
    "1. to change the measurement units\n",
    "2. to make the variable more amenable to analysis\n",
    "\n",
    "As an example of the first reason, suppose we want the lot areas to be in acres instead of square feet. Since there are 43560 square feet in an acre, this requires dividing each lot area by 43560. We can **broadcast** the division over the entire `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lot Area\"] / 43560"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to store the results as a new variable in the `DataFrame`, we simply assign the `Series` to a new column in the `DataFrame`. The command below does two things: creates a new column in the `DataFrame` called \"Lot Area (acres)\" _and_ populates it with the values from the `Series` above. (See? it's all the way on the right!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lot Area (acres)\"] = df[\"Lot Area\"] / 43560\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second reason for transforming quantitative variables is to make them more amenable to analysis. To see why a variable might not be amenable to analysis, let's take a look at a histogram of lot areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Lot Area\"].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few homes with such extreme lot areas that we get virtually no resolution at the lower end of the distribution. Over 95% of the observations are in a single bin of this histogram. In other words, this variable is extremely **skewed**.\n",
    "\n",
    "One way to improve this histogram is to use more bins. But this does not solve the fundamental problem: we need more resolution at the lower end of the scale and less resolution at the higher end. One way to spread out the values at the lower end of a distribution and to compress the values at the higher end is to take the logarithm (provided that the values are all positive). Log transformations are particularly effective at dealing with right-skewed data.\n",
    "\n",
    "The log function is not built into Python or `pandas`. We have to import the log function from a library called `numpy`, which contains many functions and data structures for numerical computations. In fact, `pandas` is built on top of `numpy`. When we apply `numpy`'s `log` function to a `pandas` `Series`, the function is automatically broadcast over the elements of the `Series`, returning another `Series`. Let's save the results to a variable called \"log(Lot Area)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"log(Lot Area)\"] = np.log(df[\"Lot Area\"])\n",
    "df[\"log(Lot Area)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are not very interpretable on their own, but if we make a histogram of these values, we see that the lower end of the distribution is now more spread out, and the extreme values are not so extreme anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"log(Lot Area)\"].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible for a log transformation to overcorrect for skew. For example, the \"SalePrice\" variable is also right-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SalePrice\"].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we take logs, the distribution becomes somewhat left-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(df[\"SalePrice\"]).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a transformation that makes the resulting distribution more symmetric?\n",
    "\n",
    "In fact, log is just one transformation in a whole family of transformations. Because the transformations in this family involve raising the values to some power, the statistician John Tukey called this the **ladder of powers**:\n",
    "\n",
    "$$ x(\\lambda) = \\begin{cases} x^\\lambda & \\lambda > 0 \\\\  \\log(x) & \\lambda = 0 \\\\ -x^\\lambda & \\lambda < 0 \\end{cases} $$\n",
    "\n",
    "$\\lambda = 1$ corresponds to no transformation at all. As we decrease $\\lambda$, the distribution becomes more left-skewed (which is useful if the original distribution was right-skewed). Since log ($\\lambda = 0$) was an overcorrection, let's back off and increase $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"SalePrice\"] ** .3).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be better. We can move $\\lambda$ up and down the ladder until the distribution is the shape we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why $\\lambda = 0$ corresponds to $\\log$\n",
    "\n",
    "You might have noticed that it does not make sense to use the transformation $x^0$ for $\\lambda = 0$, since anything raised to the zero power equals 1. But why is $\\log(x)$ the right function to replace $x^0$?\n",
    "\n",
    "The answer has to do with calculus. We want to understand the behavior of $x^\\lambda$ as $\\lambda$ approaches 0. To do this properly, we actually need to consider the function\n",
    "\n",
    "$$\\frac{x^\\lambda - 1}{\\lambda}.$$\n",
    "\n",
    "Subtracting 1 and dividing by $\\lambda$ are just constants that shift and scale the distribution; they do not affect the overall shape of the distribution. Therefore, the histogram of $x^\\lambda$ will look the same as the histogram of $(x^\\lambda - 1) / \\lambda$; only the axes will be different.\n",
    "\n",
    "Using calculus, you can show that the limit of the above function as $\\lambda$ approaches 0 is:\n",
    "\n",
    "$$\\lim_{\\lambda \\to 0} \\frac{x^\\lambda - 1}{\\lambda} = \\log(x).$$\n",
    "\n",
    "(Challenge: prove this!) This is why it makes sense to slot $\\log(x)$ in for $x^0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Mathematical Functions in Numpy\n",
    "\n",
    "You might wonder what other mathematical functions are available in `numpy` besides `log`. For one, there is `log10`, which implements the base-10 logarithm. (By default, `np.log` is the natural logarithm, base-$e$.) \n",
    "\n",
    "[Here is an exhaustive list of the mathematical functions](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.math.html). All of these functions are compatible with `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables\n",
    "\n",
    "Categorical variables sometimes also require transformation, although for different reasons than quantitative variables. With categorical variables, the values are usually labels, so it does not make sense to take logarithms or to raise them to powers. However, we might want to change the labels of the categories.\n",
    "\n",
    "For example, according to the [data documentation](https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt), the categorical variable \"Heating QC\" (heating quality and condition) in the Ames data set has five categories: excellent, good, average/typical, fair, and poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Heating QC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories are currently labeled as \"Ex\", \"Gd\", \"TA\", \"Fa\", and \"Po\", which might be cryptic to a reader. We might want to replace them with more descriptive labels. This requires a transformation.\n",
    "\n",
    "To do this, we can use the `.map()` method of `Series`. This method takes as input a dictionary that specifies the mapping between the current labels and the desired labels. So, for example, if we want all instances of \"Ex\" to be replaced by \"Excellent\", we would add the key \"Ex\" to this dictionary, with a value of \"Excellent\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Heating QC\"].map({\n",
    "    \"Ex\": \"Excellent\",\n",
    "    \"Gd\": \"Good\",\n",
    "    \"TA\": \"Average\",\n",
    "    \"Fa\": \"Fair\",\n",
    "    \"Po\": \"Poor\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we make a bar chart, the labels will come out correctly. We just have to make sure they come out in the order we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Heating QC\"].map({\n",
    "       \"Ex\": \"Excellent\",\n",
    "       \"Gd\": \"Good\",\n",
    "       \"TA\": \"Average\",\n",
    "       \"Fa\": \"Fair\",\n",
    "       \"Po\": \"Poor\"\n",
    "}).value_counts()[[\"Poor\", \"Fair\", \"Average\", \"Good\", \"Excellent\"]].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations of categorical variables are not always merely cosmetic. For example, we may want to combine several categories into one. The code below turns heating quality into a binary categorical variable (acceptable / unacceptable), according to whether the heating quality is at least average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Heating QC Binary\"] = df[\"Heating QC\"].map({\n",
    "       \"Ex\": \"Acceptable\",\n",
    "       \"Gd\": \"Acceptable\",\n",
    "       \"TA\": \"Acceptable\",\n",
    "       \"Fa\": \"Unacceptable\",\n",
    "       \"Po\": \"Unacceptable\"\n",
    "})\n",
    "\n",
    "df[\"Heating QC Binary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binary variable contains less information than the original variable, but we may not need the finer-grained detail about the heating, if all we want to know is whether it is acceptable or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Heating QC Binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Variables\n",
    "\n",
    "We can also create new variables out of multiple existing variables. For example, in the current data set, the information about when a house was sold is spread across two variables, \"Yr Sold\" and \"Mo Sold\" (1-12 indicating the month). We can combine these two variables into one, by dividing the month the house was sold by 12 and then adding that to the year. So for example, this new variable would equal 2010.5 if the house was sold in June 2010 and 2006.75 if it was sold in September 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date Sold\"] = df[\"Yr Sold\"] + df[\"Mo Sold\"] / 12\n",
    "df[\"Date Sold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the division by 12 is _broadcast_ over the elements of the `Series`, and the addition of the two `Series` is elementwise.\n",
    "\n",
    "Another example of a variable that can be derived from two existing variables is the _cost per square foot_, which is a common way to compare prices of different-sized homes. To calculate the cost per square foot of a home, we can simply divide the two `Series`, and the division will be elementwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cost per Sq Ft\"] = df[\"SalePrice\"] / df[\"Gr Liv Area\"]\n",
    "df[\"Cost per Sq Ft\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationships Between Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's start by visualizing the relationship between the square footage (of the dwelling) and the sale price, both of which are quantitative variables. To do this, we can make a **scatterplot**. In a scatterplot, each observation is represented by a point. The $(x, y)$ coordinates of each point represent the values of two variables for that observation.\n",
    "\n",
    "To make a scatterplot in `pandas`, we use the `.plot.scatter()` method of `DataFrame`. Since there are multiple columns in the `DataFrame`, we have to specify which variable is $x$ and which variable is $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.plot.scatter(x=\"Gr Liv Area\", y=\"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that square footage (of the dwelling) and the sale price have a positive relationship. That is, the greater the living area, the higher the sale price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "To summarize the relationship between two quantitative variables $X$ and $Y$, we can report the _covariance_ between them, defined as \n",
    "\n",
    "$$ \\text{Cov}[X, Y] = \\frac{1}{n - 1} \\sum_x \\sum_y (x - \\text{mean}[X]) (y - \\text{mean}[Y])$$\n",
    "\n",
    "The sign of the covariance will match the direction of the relationship between the two variables. The figures below illustrate why. If two variables are positively related, then the scatterplot might look as follows, with most points in the upper-right and lower-left quadrants (when you divide up the plane into four quadrants based on the means of $X$ and $Y$).\n",
    "\n",
    "![](../images/positive_cov.png)\n",
    "\n",
    "Each point on this scatterplot contributes to the sum that makes up the covariance. Any point in the upper-right quadrant (where $x$ and $y$ are both greater than their respective means) has a positive contribution, since the product of two positive numbers is positive. A point in the lower-left quadrant (where $x$ and $y$ are both less than their respective means) also has a positive contribution, since the product of two negative numbers is also positive. Therefore, on the whole, the covariance will be positive for two variables with a positive relationship.\n",
    "\n",
    "We can also consider two variables with a negative relationship. A scatterplot of two negatively-related variables might look as follows, with most points in the upper-left and lower-right quadrants. Points in both of these quadrants will have a negative contribution towards the covariance, since the product of a positive and a negative number is negative.\n",
    "\n",
    "![](../images/negative_cov.png)\n",
    "\n",
    "What does it mean for the covariance to be _zero_? It does not necessarily mean that there is _no_ relationship at all between the two variables; it just means that the two variables do not move in a consistent direction. For example, the two variables below have _zero_ covariance because the negative contributions from the upper-left and lower-right quadrants perfectly cancel out the positive contributions from the upper-right and lower-left quadrants. However, it would be inaccurate to say that $X$ and $Y$ have _no_ relationship; they have a strong relationship, but it just is not consistently in one direction.\n",
    "\n",
    "![](../images/zero_cov.png)\n",
    "\n",
    "To calculate the covariance between two quantitative variables, we use the `.cov()` method in `pandas`. This method is attached to one `Series` and takes another `Series` of the same length as input. It returns the covariance between the two `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"Gr Liv Area\"].cov(housing_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance between the two variables is positive, as should be apparent from the scatterplot above. Larger houses sell for higher prices.\n",
    "\n",
    "One criticism of the covariance is that the value itself is difficult to interpret, and covariances are not comparable across different variables.  As we did with the $\\chi^2$ distance in the previous section, we can normalize the covariance. This _normalized covariance_ is called the **correlation** and is symbolized $r$:\n",
    "\n",
    "$$ r = \\frac{\\text{Cov}[X, Y]}{\\text{SD}[X] \\text{SD}[Y]} $$\n",
    "\n",
    "Note that formally this is the [Pearson Correlation Coefficient for a population](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), but we can just call it the correlation coefficient for now.\n",
    "\n",
    "The correlation has all of the important properties of covariance: \n",
    "\n",
    "- A positive correlation indicates a positive relationship between the variables. As one increases, so does the other.\n",
    "- A negative correlation indicates a negative relationship between the variables. As one increases, the other tends to decrease.\n",
    "- A zero correlation means that the two variables do not move in a consistent direction, but does not necessarily mean that they have _no_ relationship.\n",
    "\n",
    "But the correlation is also guaranteed to be between $-1$ and $1$, so it can be compared across data sets.\n",
    "\n",
    "What does a maximal correlation of $\\pm 1$ mean? It means that the data fall perfectly along a line.\n",
    "\n",
    "![](../images/corr_1.png)\n",
    "\n",
    "Correlation is calculated in `pandas` in much the same way that covariance is, using the `.corr()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[\"Gr Liv Area\"].corr(housing_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the covariance, the correlation $r$ is positive, but it is a number between $-1$ and $+1$. $r=+1$ would mean that all of the points on the scatterplot fell perfectly along a line (with positive slope). Although the points in the scatterplot do not all fall perfectly on a line, they do seem to hover around an underlying line. This explains why the covariance is close to, but not equal to, $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Variables and Beyond\n",
    "So far in this chapter, we have seen a few ways to summarize and visualize the relationship between two variables. But what if we are working with three or more variables? This section discusses some strategies for dealing with multivariate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Aesthetics to Variables\n",
    "\n",
    "In Section 3.3, we made a scatterplot showing the relationship between living area and sale price. What if we also want to understand how number of bedrooms enters into the equation?\n",
    "\n",
    "One possibility is to make a three-dimensional scatterplot. However, 3D plots are often misleading when represented in two dimensions, and they don't generalize well to even higher dimensions. A better approach is to use other _aesthetics_ of the plot, such as the color or size of the points, to represent additional variables. \n",
    "\n",
    "The `.plot.scatter()` function in `pandas` allows us to control four aesthetics of a scatterplot. We've seen two already:\n",
    "\n",
    "- `x=`: the variable on the $x$-axis\n",
    "- `y=`: the variable on the $y$-axis\n",
    "\n",
    "but there are two more:\n",
    "\n",
    "- `c=`: the colors of the points (either the name of a variable in the `DataFrame` or an array specifying the color of each point)\n",
    "- `s=`: the sizes of the points (must be an array specifying the size of each point)\n",
    "\n",
    "For example, to use color to represent the number of bedrooms, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.plot.scatter(x=\"Gr Liv Area\", y=\"SalePrice\", \n",
    "                        c=\"Bedroom AbvGr\", alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the colors become darker as you move down the plot. This means that, holding living area constant, a house is less expensive the _more_ bedrooms it has. (Why do you think this is?)\n",
    "\n",
    "Now, number of bedrooms is a quantitative variable. What if we wanted to visualize how a categorical variable, such as building type, interacts with these two quantitative variables (living area and sale price)? We have to manually construct the array of colors using the `.map()` function we learned in Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = housing_df[\"Bldg Type\"].map({\n",
    "    \"1Fam\": \"blue\",\n",
    "    \"TwnhsE\": \"green\",\n",
    "    \"Twnhs\": \"green\",\n",
    "    \"Duplex\": \"red\",\n",
    "    \"2fmCon\": \"orange\"\n",
    "})\n",
    "\n",
    "housing_df.plot.scatter(x=\"Gr Liv Area\", y=\"SalePrice\", \n",
    "                        c=cols, alpha=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Multiples\n",
    "\n",
    "Rather than try to pack all of the variables into a single plot, we can juxtapose several plots or \"facets\", each showing the data from a slightly different angle. Edward Tufte coined the term \"small multiples\" for this type of graphic.\n",
    "\n",
    "For example, rather than use color to represent building type, we could have made 5 separate scatterplots, one for each building type, and arranged them in a row for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies a 1 x 5 grid of plots, figsize in inches\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 4))\n",
    "\n",
    "bldg_types = housing_df[\"Bldg Type\"].unique()\n",
    "for ax, bldg_type in zip(axes, bldg_types):\n",
    "    housing_type = housing_df[housing_df[\"Bldg Type\"] == bldg_type]\n",
    "    housing_type.plot.scatter(x=\"Gr Liv Area\", y=\"SalePrice\", ax=ax)\n",
    "    ax.set_title(bldg_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the goal of such a graphic is to facilitate comparison, which is difficult when the $x$- and $y$-axes of the facets are so different. Since the facets are aligned horizontally, it makes sense to use a common $y$-axis for all of them. We can do this by specifying `sharey=True` in `plt.subplots()`. (There is also a corresponding `sharex=` argument.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(10, 4), sharey=True)\n",
    "\n",
    "bldg_types = housing_df[\"Bldg Type\"].unique()\n",
    "for ax, bldg_type in zip(axes, bldg_types):\n",
    "    housing_type = housing_df[housing_df[\"Bldg Type\"] == bldg_type]\n",
    "    housing_type.plot.scatter(x=\"Gr Liv Area\", y=\"SalePrice\", ax=ax)\n",
    "    ax.set_title(bldg_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharing the $y$-axes between the facets also resolved another issue---the colliding $y$-axis labels---since now only the first plot in the figure has an $y$-axis label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar of Graphics\n",
    "\n",
    "The **grammar of graphics** organizes the ideas above into a coherent philosophy. The key insight is that a graphic can be specified by mapping its \"aesthetics\" (e.g., color, size, $x$-axis, column facet) to variables in a data set. Although `pandas` provides some support for this philosophy (as we have seen above), the process is tedious and often requires writing boilerplate code. For example, in order to use color to represent building type, we had to manually map each building type to a color. Libraries based on the grammar of graphics provide a more friendly interface and hide this complexity from the user.\n",
    "\n",
    "Software packages that implement the grammar of graphics include `ggplot2` in R and [Altair](https://altair-viz.github.io/) in Python. Since we are working in Python, we will use Altair. The first step is to import the package.  You will need to install this package on the data science docker image.  If you want go check them out for your final project.  [Seaborn](https://seaborn.pydata.org/) is another package we have discussed which allows for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "When there are three or more variables, summarizing the relationships can be difficult, so it is usually more fruitful to produce a visualization. That said, there are a few commonly used summary statistics for multivariate data.\n",
    "\n",
    "The **covariance matrix** is exactly what its name implies; it is a matrix whose $(i, j)$th entry is the correlation between variable $i$ and variable $j$. It is obtained by calling `.cov()` on a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\"Gr Liv Area\", \n",
    "             \"Bedroom AbvGr\", \n",
    "             \"Full Bath\", \n",
    "             \"SalePrice\"]\n",
    "\n",
    "housing_df[variables].cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the **correlation matrix** is just the corresponding matrix of correlations. All of its entries are between $-1$ and $+1$. It is obtained by calling `.corr()` on a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df[variables].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "The following questions continue using the `ames` data. Refer to the [data documentation](https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt) if you have any trouble finding or understanding a variable in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** What happens if you leave out a category in the dictionary that you pass to `.map()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE and EXPLAIN AS COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** The number of bathrooms is typically reported as a decimal to allow for half bathrooms (i.e., bathrooms without a shower). In this data set, the number of full bathrooms and the number of half bathrooms are separate variables. Create a new variable with the number of bathrooms in each home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE and EXPLAIN AS COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** Create a categorical variable that indicates whether or not a home has a pool.  \n",
    "\n",
    "*Hint: we can use the [map function...](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) because it can take a function.. or you can use the filtering learned in the last lab...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE and EXPLAIN AS COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.** There are four types of utilities: electricity, gas, water, and sewage. Right now, the combination of utilities in a home is encoded in a single variable called \"Utilities\". Convert this variable into four boolean variables, each one indicating whether or not a home has a particular utility.\n",
    "\n",
    "*Hint: Check the values before you start coding...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining questions deal with the Tips data set (`./data/tips.csv`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.** Make a visualization that shows the distribution of the total bills. Transform the variable first so that it is approximately symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE and EXPLAIN AS COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6.** Suppose the total bill + tip are divided evenly among the people in each party. Which table paid the most _per person_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE and EXPLAIN AS COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.** Make a visualization that shows how busy the restaurant is by day. Your visualization should display the full name of each day, i.e., \"Thursday\" instead of \"Thur\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE and EXPLAIN AS COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8.** Make a scatterplot showing the relationship between the tip and the total bill. Use color to indicate whether the tipper was male or female and the size of each point to represent the party size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9.** Calculate the correlation matrix summarizing the pairwise relationships between the quantitative variables in this data set. Interpret what you see. Which pair of variables in this data set have the highest correlation with each other? A question to answer is: **Why does it make sense that all of the diagonal entries of this matrix are equal to $1.0$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Answer Here**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10.** To build your intuition about correlation, play this [correlation guessing game](http://guessthecorrelation.com/). There is even a two-player mode that allows you to play against a friend in the class.  How long did you last?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you have filled out all the questions, submit via [Tulane Canvas](https://tulane.instructure.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
